{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrega 2 - Aprendizaje Bayesiano\n",
    "\n",
    "### Grupo 9:\n",
    "     - J. Gu       C.I 5.509.557-9\n",
    "     - M. Nuñez    C.I 5.225.262-3\n",
    "     - L. Pereira  C.I 5.268.309-4\n",
    "     \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importaciones\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import KBinsDiscretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prueba de Chi-cuadrado para columnas categóricas:\n",
      "Columna: time, Chi-cuadrado: 68686.32720282467, p-valor: 0.0\n",
      "Columna: trt, Chi-cuadrado: 12.727324961369058, p-valor: 0.0003603516000424519\n",
      "Columna: age, Chi-cuadrado: 22.790525861926426, p-valor: 1.806540870798201e-06\n",
      "Columna: wtkg, Chi-cuadrado: 1.3146081081741743, p-valor: 0.25156202412010753\n",
      "Columna: hemo, Chi-cuadrado: 0.2437032164540472, p-valor: 0.6215441578565497\n",
      "Columna: homo, Chi-cuadrado: 2.1359663906960566, p-valor: 0.14387976345739725\n",
      "Columna: drugs, Chi-cuadrado: 4.606804351787607, p-valor: 0.03184532471773235\n",
      "Columna: karnof, Chi-cuadrado: 8.266037824718222, p-valor: 0.004039356372358083\n",
      "Columna: oprior, Chi-cuadrado: 3.5598055788336604, p-valor: 0.0591946717300646\n",
      "Columna: z30, Chi-cuadrado: 15.148901863277914, p-valor: 9.935608318167467e-05\n",
      "Columna: zprior, Chi-cuadrado: 0.0, p-valor: 1.0\n",
      "Columna: preanti, Chi-cuadrado: 20434.61921331491, p-valor: 0.0\n",
      "Columna: race, Chi-cuadrado: 4.768996945701265, p-valor: 0.028976703450220735\n",
      "Columna: gender, Chi-cuadrado: 0.7491170526457296, p-valor: 0.3867559211756265\n",
      "Columna: str2, Chi-cuadrado: 13.489441526287175, p-valor: 0.00023990958855649644\n",
      "Columna: strat, Chi-cuadrado: 15.079950204254647, p-valor: 0.0001030520467411153\n",
      "Columna: symptom, Chi-cuadrado: 29.544678011859226, p-valor: 5.4642484543769506e-08\n",
      "Columna: treat, Chi-cuadrado: 8.929982246704148, p-valor: 0.0028052707322557763\n",
      "Columna: offtrt, Chi-cuadrado: 11.750698419860672, p-valor: 0.0006082041135064833\n",
      "Columna: cd40, Chi-cuadrado: 2955.768750602407, p-valor: 0.0\n",
      "Columna: cd420, Chi-cuadrado: 14412.560686527222, p-valor: 0.0\n",
      "Columna: cd80, Chi-cuadrado: 2133.193099048195, p-valor: 0.0\n",
      "Columna: cd820, Chi-cuadrado: 171.98559106153945, p-valor: 2.7258877182786674e-39\n",
      "\n",
      " Tras las Pruebas Chi-cuadrado, las columnas a eliminar son:\n",
      "Columna a borrar: wtkg\n",
      "Columna a borrar: hemo\n",
      "Columna a borrar: homo\n",
      "Columna a borrar: oprior\n",
      "Columna a borrar: zprior\n",
      "Columna a borrar: gender\n"
     ]
    }
   ],
   "source": [
    "# Cargar el dataset con encabezados\n",
    "DATASET_FILE = 'lab1_dataset.csv'\n",
    "dataset = pd.read_csv(DATASET_FILE, sep=\",\")\n",
    "\n",
    "# Guardar los nombres de las columnas\n",
    "column_names = dataset.columns[1:]  # Excluir la primera columna (ID del paciente)\n",
    "\n",
    "# Eliminar la primera columna (ID del paciente)\n",
    "dataset = dataset.drop(dataset.columns[0], axis=1)\n",
    "\n",
    "# Definir las columnas categóricas manualmente\n",
    "columnas_categoricas = [1, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18]\n",
    "\n",
    "# Extraer los atributos y la etiqueta\n",
    "atributos = dataset.iloc[:, 1:].values  # Todas las columnas menos la primera (la etiqueta)\n",
    "etiqueta = dataset.iloc[:, 0].values    # Primera columna como etiqueta\n",
    "\n",
    "# Crear un KBinsDiscretizer para discretizar los valores continuos\n",
    "discretizer = KBinsDiscretizer(n_bins=2, encode='ordinal', strategy='uniform')\n",
    "\n",
    "# Aplicar la discretización solo a las columnas continuas\n",
    "for col in range(atributos.shape[1]):\n",
    "    if col not in columnas_categoricas:\n",
    "        # Discretizar la columna continua\n",
    "        atributos[:, col:col+1] = discretizer.fit_transform(atributos[:, col:col+1])\n",
    "\n",
    "# Convertir `etiqueta` a una forma de columna para la concatenación\n",
    "etiqueta_columna = etiqueta.reshape(-1, 1)\n",
    "\n",
    "# Conatenar `etiqueta` con los atributos discretizados\n",
    "dataset_discretizado = np.hstack([etiqueta_columna, atributos])\n",
    "\n",
    "# Ajustar los nombres de las columnas\n",
    "column_names_discretizado = ['etiqueta'] + list(column_names[1:])\n",
    "\n",
    "# Convertir el array discretizado en un DataFrame\n",
    "dataset_discretizado_df = pd.DataFrame(dataset_discretizado, columns=column_names_discretizado)\n",
    "\n",
    "# Definir la variable objetivo\n",
    "y = dataset['cid'] \n",
    "\n",
    "# Definir manualmente las columnas categóricas\n",
    "columnas_categoricas = ['time','trt','age','wtkg', 'hemo', 'homo', 'drugs','karnof', 'oprior', 'z30', 'zprior','preanti','race', 'gender', 'str2', 'strat', 'symptom', 'treat', 'offtrt','cd40','cd420','cd80','cd820']\n",
    "\n",
    "# Seleccionar las columnas categóricas que ya son numéricas\n",
    "X_categoricas_encoded = dataset[columnas_categoricas]\n",
    "\n",
    "# Aplicar la prueba de Chi-cuadrado\n",
    "chi_scores, p_values = chi2(X_categoricas_encoded, y)\n",
    "\n",
    "# Mostrar los resultados del Chi-cuadrado para las columnas categóricas\n",
    "print(\"\\nPrueba de Chi-cuadrado para columnas categóricas:\")\n",
    "for i, col in enumerate(columnas_categoricas):\n",
    "    print(f\"Columna: {col}, Chi-cuadrado: {chi_scores[i]}, p-valor: {p_values[i]}\")\n",
    "\n",
    "print(\"\\n Tras las Pruebas Chi-cuadrado, las columnas a eliminar son:\")\n",
    "for i, col in enumerate(columnas_categoricas):\n",
    "    if p_values[i] > 0.05:\n",
    "        print(f\"Columna a borrar: {col}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este informe es implementar y evaluar un modelo basado en aprendizaje bayesiano, y capaz de soportar problemas causados por probabilidades condicionales iguales a cero incorporando un parámetro m, el cual indica el tamaño equivalente de muestra y el cual se utilizará para generar un m-estimador de las probabilidades condicionales. \n",
    "\n",
    "Se evaluará las herramientas de metodologías vistas en el curso, evaluando sobre cuales son las más adecuadas en este caso y, en particular, se aplicarán técnicas de feature selection, cross validation, se presentará la matriz de confusión y la curva de precision-recall para todos los casos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Diseño"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se presentaran las evaluaciones de las herramientas de metodologías vistas en el curso aplicadas a este problema, una descripción del procesamiento de datos realizado y los métodos de evaluación utilizados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Preprocesamiento de datos\n",
    "  Para nuestro laboratorio, comenzamos obteniendo el conjunto de datos y realizando una limpieza inicial. La primera acción fue eliminar la columna 0, que correspondía al identificador del paciente. Esta columna no aportaba información relevante para la predicción, ya que es simplemente un identificador único y no tiene correlación con las características de salud que queremos evaluar.\n",
    "#### 2.1.1 Identificación de atributos categóricos y continuos\n",
    "  A continuación, identificamos cuáles atributos eran categóricos y cuáles eran continuos. Esta diferenciación es crucial porque los atributos categóricos representan cualidades discretas, como tipos o categorías, mientras que los atributos continuos son valores numéricos que pueden tomar cualquier valor dentro de un rango. Tratar los atributos categóricos como continuos podría llevar a resultados erróneos.\n",
    "  \n",
    "  Para asegurarnos de que los atributos categóricos fueran tratados adecuadamente, los definimos explícitamente antes del entrenamiento del modelo. Esto fue necesario ya que todos los atributos del conjunto de datos brindados son numéricos, pero algunos de ellos son esencialmente categóricos (teniendo 0 ante una categoría, 1 ante otra, etc.).\n",
    "   \n",
    "  Al analizar el esquema del conjunto de datos brindado, vimos que éste especificaba cuáles eran los atributos categóricos y cuáles no. Teniendo esto en cuenta, decidimos que nuestra implementación del árbol de decisión recibiera como parámetro una lista con los índices de las columnas que eran categóricas. De esta forma diferenciamos entre los atributos categóricos y numéricos y actuamos en consecuencia dependiendo del caso.\n",
    "#### 2.1.2 Enfoques de Procesamiento\n",
    "  Adoptamos dos enfoques para manejar los atributos continuos y categóricos en el procesamiento de datos:\n",
    "  - Definición de Rangos dentro del Algoritmo: En el primer enfoque permitimos que el algoritmo determinara los mejores puntos de corte durante su ejecución. Esto se realizó durante el proceso de recursión del algoritmo, donde se evaluaban diferentes divisiones de los datos para maximizar la ganancia de información. Este enfoque es más dinámico y se adapta mejor a las características específicas de los datos de entrenamiento en cada pliegue. La implementación de este algoritmo que elige los mejores puntos de corte es explicada más adelante en la sección 2.2.1.\n",
    "  \n",
    "  - Discretización previa al entrenamiento (preprocesamiento): En el segundo enfoque, discretizamos los valores continuos antes del entrenamiento. La discretización implica dividir los valores continuos en intervalos o categorías, convirtiéndolos así en atributos discretos. Para determinar los mejores puntos de corte (intervalos) para la discretización, analizamos el conjunto de datos completo utilizando el mismo criterio que en el algoritmo de definición de rangos dentro de ID3, generando 2 modelos, uno en el que solamente permitimos que el preprocesamiento divida en 2 rangos los valores numéricos, como si fuera max_range_split = 2, y otro preprocesamiento que permita dividar en 2 o 3 rangos los valores numéricos (max_range_split = 3).\n",
    "  \n",
    "  La diferencia entre ambos enfoques radica en que en el segundo hallamos los mejores puntos de corte una única vez antes de ingresar al algoritmo, por lo que el algoritmo interpreta a todos los atributos como categóricos desde su comienzo, mientras que en el primer enfoque se hallan los mejores puntos de corte en cada rama del árbol que se evalúen valores numéricos. \n",
    "  \n",
    "  La idea es evaluar la precisión del algoritmo ante los dos enfoques para visualizar ante cual se desempeña mejor.\n",
    "  \n",
    "#### 2.1.3 Uso de OneHotEncoder para atributos categóricos\n",
    "Para el manejo de atributos categóricos con los algoritmos de scikit-learn, utilizamos el OneHotEncoder. Este transformador es una herramienta que convierte cada categoría de un atributo categórico en una columna binaria separada. Si un atributo categórico tiene tres posibles valores, el OneHotEncoder creará tres columnas binarias (una para cada valor). Este enfoque es útil porque permite que los modelos interpreten correctamente los datos categóricos, ya que evita asignar valores ordinales (como 0, 1, 2) que podrían implicar un orden que no existe realmente. Esto mejora la calidad de las predicciones y evita sesgos inducidos por un mal manejo de los datos categóricos, y es necesario ya que sin él, los modelos de scikit-learn interpretan por defecto que todos los atributos son numéricos, por lo que el modelo que se genere no será del todo correcto.\n",
    "\n",
    "#### 2.1.4 Partición del conjunto de datos\n",
    "A la hora de decidir cómo ibamos a particionar el conjunto de datos para utilizar una parte para entrenamiento y otra para evaluación, decidimos utilizar la division en 5 partes del conjunto, ya que cómo método de evaluación pensamos utilizar validación cruzada. Punto que será mejor desarrollado en la sección de evaluación.\n",
    "\n",
    "\n",
    "### 2.2 Consideraciones sobre algoritmo bayesiano\n",
    "Para implementar el algoritmo ID3, nos basamos fuertemente en el algoritmo visto en el teórico del curso. En esta sección explicaremos las consideraciones que tuvimos a la hora de implementar el algoritmo ID3 que escapan de la base del algoritmo, y como éstas pueden afectar los resultados posteriores.\n",
    "\n",
    "#### 2.2.1 Cálculo de ganancia y entropía\n",
    "Los cálculos de ganancia y entropía son iguales a como fueron presentados en el curso. Las únicas consideraciones que tuvimos fueron con el hiperparámetro max_range_split y con la decisión de retornar 0 ante algunos casos borde. \n",
    "Dado que nos interesaba observar los resultados de nuestra implementación con max_range_split igual a 2 y 3, no generalizamos en la implementación que max_range_split pueda tener cualquier valor, sino que solo consideramos esos casos. Esto se hizo ya que la generalización del hiperparámetro hacía que la implementación tuviera que tener varias complejidades extras que entendimos no serían necesarias para experimentar con el conjunto de datos dado.\n",
    "\n",
    "Por otro lado, decidimos que al calcular la ganancia de un valor numérico, ante el caso de que alguno de los puntos de corte seleccionados dejara alguno de los subconjuntos vacío, retornaríamos 0 como ganancia. \n",
    "Luego, en el algoritmo se recorren todos los atributos y se elige aquel que genere máxima ganancia. Ante el caso en el que todos los atributos generen ganancia 0, se retorna el valor de etiqueta que más veces aparezca en esa rama y se finaliza la recursión, ya que si bajar un nivel más por el árbol no nos genera ganancia, deberíamos mantenerlo lo más genérico posible.\n",
    " \n",
    "Esto, por otro lado, implicitamente genera que, sin necesidad de ir eliminando los atributos que ya se utilizaron en el árbol, no estemos eligiendo más de una vez en el árbol un atributo categórico (ya que su ganancia luego es 0 y no sería seleccionado), pero si lo permite para atributos numéricos utilizando distintas particiones al profundizar en las ramas.\n",
    "\n",
    "El hecho de que los atributos numéricos puedan ser reutilizados como atributos en el árbol tiene que tomarse con cuidado ya que podría generar, dependiendo de las características del conjunto de datos, una rama infinita en la que se particione por dicho atributo numérico infinitas veces. En el caso particular del conjunto de datos utilizado, esto no sucedió y por ende solamente se registra su posibilidad de ocurrencia pero no fue tenida en cuenta su resolución en la implementación.\n",
    "\n",
    "#### 2.2.2 ¿Qué puntos de corte utilizar ante atributos numéricos?\n",
    "Como tercer consideración, tuvimos que ver cómo ibamos a seleccionar los puntos de corte para el caso de la división de los atributos numéricos. Como fue discutido en clase, se podría identificar los posibles puntos de corte ordenando el conjunto de datos de acuerdo a ese atributo y verificando en qué valores la etiqueta cambia su valor de positivo a negativo o viceversa. Al haber un cambio de valor, el punto medio entre los dos valores del atributo en los que se da ese cambio sería un posible punto de corte.\n",
    "\n",
    "Esto sin embargo puede llegar a generar múltiples puntos de corte, mientras que nuestro algoritmo solamente permitía 1 o 2 puntos (dependiendo del valor que se le diera a max_range_split). Para solventar esta situación decidimos tomar todas las combinaciones de puntos de corte, identificadas previamente, de a 1 y 2 puntos, calcular la ganancia que generaría utilizarlos efectivamente como puntos de corte, y finalmente quedarnos con el/los punto/s de corte que nos generen ganancia máxima.\n",
    "\n",
    "Al realizar esta implementación tuvimos en cuenta que podía suceder que los tiempos de ejecución fueran demasiado altos, ya que el tomar todas las combinaciones y calcularles la ganancia es algo bastante ineficiente dado el orden que tiene, pero, al probar la implementación con el conjunto de datos brindado, descubrimos que igualmente se ejecutaba en pocos minutos, por lo que decidimos mantenerlo de esa forma. No obstante, entendemos que dado otro conjunto de datos con mayor cantidad de atributos y/o mayor cantidad de filas, esta opción podría tardar demasiado tiempo, en ese caso se podría optar por soluciones como tomar N combinaciones de los datos para calcularles la ganancia, o elegir de manera azarosa la cantidad de puntos de corte que se quiera, dados los puntos de corte encontrados previamente.\n",
    "\n",
    "\n",
    "\n",
    "## 2.3 Evaluación\n",
    "Se probará los distintos algoritmos utilizando el conjunto de datos «AIDS Clinical Trials Group Study 175».\n",
    "### 2.3.1 Métricas utilizadas para la evaluación de la solución\n",
    "En este estudio, la métrica principal utilizada para evaluar el rendimiento de los modelos fue la precisión. La precisión mide el porcentaje de predicciones correctas sobre el total de predicciones realizadas. Es una métrica común en problemas de clasificación, especialmente cuando las clases están balanceadas. Se define como: \n",
    "$$\n",
    "\\text{Precisión} = \\frac{\\text{Número de predicciones correctas}}{\\text{Número total de predicciones}}\n",
    "$$\n",
    "- La precisión es una métrica fácil de interpretar y proporciona una buena visión general de qué tan bien está desempeñándose el modelo en términos generales.\n",
    "\n",
    "- Desviación Estándar de la Precisión: Además de la precisión promedio, también calculamos la desviación estándar de la precisión. La desviación estándar mide la variabilidad o dispersión de las puntuaciones de precisión a través de los diferentes pliegues de la validación cruzada. Una desviación estándar baja sugiere que el modelo es consistente en diferentes subconjuntos de los datos, mientras que una desviación estándar alta podría indicar que el rendimiento del modelo es inestable o depende en gran medida de la división particular de los datos.\n",
    "\n",
    "### 2.3.2 Construcción de los conjuntos de entrenamiento, ajuste y evaluación\n",
    "Para evaluar la efectividad de los modelos de aprendizaje automático, utilizamos la técnica de validación cruzada con 5 pliegues. Este método implica dividir el dataset en cinco subconjuntos aproximadamente iguales. En cada iteración, uno de los subconjuntos se usa como conjunto de prueba, mientras que los otros cuatro se utilizan para entrenar el modelo. Este proceso se repite cinco veces, de modo que cada subconjunto se utiliza una vez como conjunto de prueba.\n",
    "\n",
    "### 2.3.3 ¿Por qué validación cruzada?\n",
    "Optar por la validación cruzada de 5 pliegues nos permitió utilizar todo el conjunto de datos para el entrenamiento y la evaluación, lo cual es beneficioso cuando se trabaja con conjuntos de datos que no son extremadamente grandes. Esta técnica también ayuda a mitigar el riesgo de sobreajuste al proporcionar una evaluación más completa del rendimiento del modelo en diferentes particiones del conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Experimentación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En las siguientes tablas se presentan los resultados obtenidos, mostrando la precisión promedio y la desviación estándar de los cinco pliegues generados por la validación cruzada para los diferentes algoritmos evaluados. En lugar de detallar los resultados individuales de cada pliegue, solo se exponen los promedios y las desviaciones estándar calculadas.\n",
    "\n",
    "Decidimos evaluar tambien los algoritmos sobre los datos de entrenamiento aparte de los datos de prueba para comprobar que los arboles de decisión tienen una alta tendencia a sobreajustar porque son muy flexibles y pueden ajustarse perfectamente a los datos de entrenamiento, capturando incluso el ruido y las anomalías.\n",
    "\n",
    "La Tabla 1 muestra los resultados obtenidos para el algoritmo ID3 con diferentes configuraciones de max_range_split y utilizando datos preprocesados, mientras que la Tabla 2 incluye los resultados de DecisionTreeClassifier, RandomForestClassifier y el algoritmo ID3 sobre datos procesados en tiempo de ejecución."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <th>Algoritmo</th>\n",
    "    <th>Datos utilizados para pruebas</th>\n",
    "    <th>Precisión promedio (%)</th>\n",
    "    <th>Desviación estándar</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>ID3 (max_range_split = 2)</td>\n",
    "    <td>Entrenamiento</td>\n",
    "    <td>98.04</td>\n",
    "    <td>0.12</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>ID3 (max_range_split = 2)</td>\n",
    "    <td>Evaluación</td>\n",
    "    <td>83.31</td>\n",
    "    <td>1.13</td>\n",
    "  </tr>    \n",
    "  <tr>\n",
    "    <td>ID3 (max_range_split = 3)</td>\n",
    "    <td>Entrenamiento</td>\n",
    "    <td>98.04</td>\n",
    "    <td>0.12</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>ID3 (max_range_split = 3)</td>\n",
    "    <td>Evaluación</td>\n",
    "    <td>83.31</td>\n",
    "    <td>1.13</td>\n",
    "  </tr>\n",
    "  <caption>Tabla 1 - Resultados de ID3 con datos preprocesados</caption>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <th>Algoritmo</th>\n",
    "    <th>Precisión promedio (%)</th>\n",
    "    <th>Desviación estándar</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>DecisionTreeClassifier (criterion = 'gini')</td>\n",
    "    <td>85.46</td>\n",
    "    <td>1.55</td>\n",
    "  </tr>    \n",
    "  <tr>\n",
    "    <td>DecisionTreeClassifier (criterion = 'entropy')</td>\n",
    "    <td>83.50</td>\n",
    "    <td>1.07</td>\n",
    "  </tr>    \n",
    "  <tr>\n",
    "    <td>DecisionTreeClassifier (criterion = 'log_loss')</td>\n",
    "    <td>83.50</td>\n",
    "    <td>1.07</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>RandomForestClassifier (criterion = 'gini')</td>\n",
    "    <td>89.15</td>\n",
    "    <td>1.22</td>\n",
    "  </tr>    \n",
    "  <tr>\n",
    "    <td>RandomForestClassifier (criterion = 'entropy')</td>\n",
    "    <td>89.20</td>\n",
    "    <td>1.34</td>\n",
    "  </tr>    \n",
    "  <tr>\n",
    "    <td>RandomForestClassifier (criterion = 'log_loss')</td>\n",
    "    <td>89.20</td>\n",
    "    <td>1.34</td>\n",
    "  </tr>\n",
    "  <tr style=\"font-weight:bold\">\n",
    "    <td>ID3 (max_range_split = 2)</td>\n",
    "    <td>84.15</td>\n",
    "    <td>1.21</td>\n",
    "  </tr>    \n",
    "  <tr style=\"font-weight:bold\">\n",
    "    <td>ID3 (max_range_split = 3)</td>\n",
    "    <td>84.38</td>\n",
    "    <td>1.34</td>\n",
    "  </tr>  \n",
    "  <caption>Tabla 2 - Resultados con datos de evaluación procesados durante la ejecución</caption>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar en la tabla 1, la precisión y desviación estándar de los modelos con preprocesamiento similar a max_range_split = 2 y 3 dieron como resultado exactamente los mismos valores. Esto se debe a que al preprocesar los valores, los mejores puntos de corte encontrados utilizando todo el conjunto de datos dieron como resultado los mismos puntos, y en ambos casos se determinó que un solo punto de corte que divide en dos rangos los atributos era lo que generaba más ganancia.\n",
    "\n",
    "Se aclara también que en la tabla 2 no se visualizan la precisión y desviación estándar de las pruebas sobre datos de entrenamiento ya que en todos los casos el resultado fue de precisión = 100% y desviación estándar = 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este laboratorio, hemos implementado y evaluado un árbol de decisión basado en el algoritmo ID3, extendido para soportar atributos numéricos mediante el hiperparámetro max_range_split. También hemos comparado los resultados obtenidos con otros modelos de árboles de decisión proporcionados por scikit-learn, como DecisionTreeClassifier y RandomForestClassifier.\n",
    "\n",
    "### 4.1 Mejores Resultados:\n",
    "Los mejores resultados en términos de precisión se obtuvieron con el modelo RandomForestClassifier, particularmente utilizando el criterio entropy y log_loss, alcanzando una precisión promedio cercana al 89.20% y con una desviación estándar relativamente baja, lo que indica una buena estabilidad del modelo. \n",
    "\n",
    "En contraste, el algoritmo ID3 implementado obtuvo su mejor precisión promedio de 84.38% cuando se utilizó max_range_split igual a 3, aunque con una desviación estándar un poco más alta que las de los modelos de RandomForestClassifier, lo cual sugiere una mayor variabilidad en el desempeño del modelo ID3.\n",
    "\n",
    "### 4.2 Relaciones Observadas:\n",
    "Al analizar los resultados, se observó que el valor del hiperparámetro max_range_split influyó en la precisión del algoritmo ID3, aunque la mejora entre max_range_split = 2 y max_range_split = 3 fue marginal. Esto sugiere que, para este conjunto de datos específico, un mayor número de puntos de corte en los atributos numéricos no necesariamente lleva a una mejora significativa en el rendimiento. Esto puede deberse, como vimos a la hora de preprocesar los valores numéricos, a que muchas veces la mayor ganancia de un conjunto de puntos de corte sigue siendo un punto individual que divida en dos rangos al conjunto, que dos puntos de corte que dividan el rango en tres. \n",
    "\n",
    "Por otro lado, al analizar los resultados de la implementacion ID3 tanto preprocesando los datos como no preprocesandolos, vimos que el modelo da mejores resultados cuando no se preprocesan los atributos numéricos como categóricos. Esto tiene sentido, ya que el algoritmo permite que se encuentren los mejores puntos de corte en cada rama del árbol, y que también se pueda reutilizar un atributo numérico con distintos puntos de corte a lo largo del árbol. Esto se pierde al preprocesar los datos, ya que estamos dandoles un valor categórico y este no varía luego dinámicamente en el modelo. \n",
    "\n",
    "Otra cosa a destacar es que al preprocesar los datos fue el único caso en el que las pruebas con datos de entrenamiento no dieron como resultado una precisión de 100% y una desviación estándar de 0, sino que los valores de precisión fueron de 98.04% y desviación de 0.14, lo que sugiere que al preprocesar los datos y categorizar los atributos numéricos previo a ingresar al algoritmo, estamos perdiendo información que luego genera esa disminución en la precisión.  \n",
    "\n",
    "También pudimos observar como varían los resultados de los algoritmos de scikit-learn al variar el criterio utilizado, para DecisionTreeClassifier vemos como el criterio 'gini' es el que obtiene la mayor precisión, mientras que en RandomForestClassifier esto sucede al revés (aunque la diferencia es marginal).\n",
    "\n",
    "En el caso de DecisionTreeClassifier, las diferencias entre gini y entropy pueden ser más pronunciadas porque cada división depende fuertemente del criterio seleccionado. gini puede ser más efectivo en conjuntos de datos donde una clase es claramente dominante, mientras que entropy puede ser mejor en conjuntos de datos más balanceados o complejos.\n",
    "\n",
    "En RandomForestClassifier, las diferencias entre los criterios tienden a disminuir. El efecto de un solo árbol que utiliza un criterio específico se diluye en el conjunto. Esto explica por qué, en nuestras observaciones, aunque hay una diferencia entre los criterios, es marginal. \n",
    "\n",
    "En conclusión, pudimos ver que el algoritmo implementado, si bien no obtuvo tanta precisión como el RandomForestClassifier, se encuentra similar al DecisionTreeClassifier, lo cual tiene sentido ya que teóricamente son el mismo algoritmo, y RandomForestClassifier es un algoritmo más potente. \n",
    "\n",
    "\n",
    "### 4.3 Posibles Mejoras:\n",
    "Para mejorar los resultados, podrían considerarse las siguientes acciones:\n",
    "\n",
    "Optimización del hiperparámetro max_range_split: Aunque solo se evaluaron los valores 2 y 3, podría ser útil explorar otros valores de max_range_split. Para esto sería necesario rever la implementación del algoritmo ya que actualmente, como se mencionó anteriormente, solamente soporta valores de 2 y 3.\n",
    "\n",
    "Implementación de nuevos hiperparámetros: Además de max_range_split, si se quisiera mejorar la precisión del modelo, se podría probar implementar otros hiperparámetros, como los que tienen los modelos vistos de scikit-learn, para ver si éstos mejoran el desempeño.\n",
    "\n",
    "Ajuste de modelos con scikit-learn: Se podrían ajustar más hiperparámetros en los modelos de scikit-learn, como el número de árboles en RandomForestClassifier o la profundidad máxima en DecisionTreeClassifier, para maximizar la precisión y minimizar la desviación estándar.\n",
    "\n",
    "Incorporación de otros métodos de validación: Aunque ya se utilizó validación cruzada en este laboratorio, implementar técnicas de validación más exhaustivas, como la búsqueda de hiperparámetros con validación cruzada en cada iteración, podría optimizar aún más los resultados.\n",
    "\n",
    "### 4.4 Conclusión General:\n",
    "El trabajo realizado permitió una comprensión profunda de cómo los distintos modelos de árboles de decisión pueden ser aplicados y ajustados a un conjunto de datos real. \n",
    "\n",
    "Por un lado, el haber implementado el algoritmo ID3 y haber conseguido un desempeño aceptable, nos permitió ver cómo funcionan estos modelos por detrás y nos hizo tener en cuenta los posibles casos borde y consideraciones que se puede tener a la hora de trabajar con conjuntos de datos.\n",
    "\n",
    "Por otro lado, aunque el algoritmo ID3 implementado mostró un buen desempeño, los modelos más avanzados de scikit-learn demostraron ser más robustos y precisos en este contexto, lo que remarca la importancia de considerar técnicas más complejas en problemas de clasificación cuando se dispone de datos suficientemente grandes y variados y se quiere tener la mayor precisión posible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
