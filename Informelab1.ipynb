{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrega 1 - Árboles de Decisión\n",
    "\n",
    "### Grupo 9:\n",
    "     - J. Gu       C.I 5.509.557-9\n",
    "     - M. Nuñez    C.I 5.225.262-3\n",
    "     - L. Pereira  C.I 5.268.309-4\n",
    "     \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este informe es implementar y evaluar un árbol de decisión basado en el algoritmo ID3 con soporte para atributos numéricos, incorporando un parámetro max_range_split, el cual indica la cantidad máxima de rangos en los que se pueden partir dichos atributos numéricos. \n",
    "\n",
    "Se realizará el preprocesamiento de datos numéricos, se entrenarán y evaluarán modelos usando tanto el ID3 modificado como los algoritmos DecisionTreeClassifier y RandomForestClassifier de scikit-learn, y se compararán los resultados obtenidos para cada enfoque.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Diseño"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección se deben presentar las decisiones tomadas a la hora de implementar el jugador, clasificador, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Preprocesamiento de datos\n",
    "  Para nuestro laboratorio, comenzamos obteniendo el dataset y realizando una limpieza inicial. La primera acción fue eliminar la columna 0, que correspondía al identificador del paciente. Esta columna no aportaba información relevante para la predicción, ya que es simplemente un identificador único y no tiene correlación con las características de salud que queremos evaluar.\n",
    "### 2.1.1 Identificación de atributos categóricos y continuos\n",
    "  A continuación, identificamos qué atributos eran categóricos y cuáles eran continuos. Esta diferenciación es crucial porque los atributos categóricos representan cualidades discretas, como tipos o categorías, mientras que los atributos continuos son valores numéricos que pueden tomar cualquier valor dentro de un rango. Tratar los atributos categóricos como continuos podría llevar a resultados erróneos. Para asegurarnos de que los atributos categóricos fueran tratados adecuadamente, los definimos explícitamente antes del entrenamiento del modelo.\n",
    "### 2.1.2 Enfoques de Preprocesamiento\n",
    "  Adoptamos dos enfoques para manejar los atributos continuos y categóricos en el preprocesamiento:\n",
    "  - Discretización previa al entrenamiento: En el primer enfoque, discretizamos los valores continuos antes del entrenamiento. La discretización implica dividir los valores continuos en intervalos o categorías, convirtiéndolos así en atributos discretos. Para determinar los mejores puntos de corte (intervalos) para la discretización, analizamos el dataset completo.\n",
    "  - Definición de Rangos dentro del Algoritmo: En el segundo enfoque, en lugar de discretizar previamente los valores continuos, permitimos que el algoritmo determinara los mejores puntos de corte durante su ejecución. Esto se realizó durante el proceso de recursión del algoritmo, donde se evaluaban diferentes divisiones de los datos para maximizar la ganancia de información. Este enfoque es más dinámico y se adapta mejor a las características específicas de los datos de entrenamiento en cada pliegue.\n",
    "  \n",
    "### 2.1.3 Uso de OneHotEncoder para atributos categóricos\n",
    "Para el manejo de atributos categóricos con los algoritmos de scikit-learn, utilizamos el OneHotEncoder. Este transformador es una herramienta que convierte cada categoría de un atributo categórico en una columna binaria separada. Si un atributo categórico tiene tres posibles valores, el OneHotEncoder creará tres columnas binarias (una para cada valor). Este enfoque es útil porque permite que los modelos de machine learning interpreten correctamente los datos categóricos, ya que evita asignar valores ordinales (como 0, 1, 2) que podrían implicar un orden que no existe realmente. Esto mejora la calidad de las predicciones y evita sesgos inducidos por un mal manejo de los datos categóricos.\n",
    "\n",
    "### 2.1.4 Partición de dataset\n",
    "Decidimos utilizar la division en 5 partes del dataset para un futuro uso de la validación cruzada que sera mejor desarrollada en la sección de evaluación\n",
    "\n",
    "\n",
    "## 2.2 Algoritmo\n",
    "En esta sección explicaremos las consideraciones que tuvimos a la hora de implementar el algoritmo ID3 y como estas pueden afectar los resultados posteriores.\n",
    "\n",
    "En primer lugar, nos basamos en el algoritmo ID3 visto en el teórico del curso, el cual utiliza los cálculos de ganancia y entropía para decidir que atributo debe utilizar. Estos cálculos son iguales a como fueron presentados, la única consideración que tuvimos fue con el hiperparámetro max_range_split. Dado que nos interesaba observar los resultados de nuestra implementación con max_range_split igual a 2 y 3, no generalizamos en la implementación que max_range_split pueda tener cualquier valor, sino que solo consideramos esos casos. Esto se hizo ya que la generalización del hiperparámetro hacía que la implementación tuviera que tener varias complejidades extras que entendimos no serían necesarias para experimentar con el conjunto de datos dado.\n",
    "\n",
    "En segundo lugar, debimos decidir cuando consideraríamos que un atributo era numérico y cuando era categórico. Al analizar el esquema del conjunto de datos brindado...\n",
    "\n",
    "\n",
    "## 2.3 Evaluación\n",
    "Se probará los distintos algoritmos utilizando el conjunto de datos «AIDS Clinical Trials Group Study 175».\n",
    "### 2.3.1 Métricas utilizadas para la evaluación de la solución\n",
    "En este estudio, la métrica principal utilizada para evaluar el rendimiento de los modelos fue la precisión. La precisión mide el porcentaje de predicciones correctas sobre el total de predicciones realizadas. Es una métrica común en problemas de clasificación, especialmente cuando las clases están balanceadas. Se define como: \n",
    "$$\n",
    "\\text{Precisión} = \\frac{\\text{Número de predicciones correctas}}{\\text{Número total de predicciones}}\n",
    "$$\n",
    "- La precisión es una métrica fácil de interpretar y proporciona una buena visión general de qué tan bien está desempeñándose el modelo en términos generales.\n",
    "\n",
    "- Desviación Estándar de la Precisión: Además de la precisión promedio, también calculamos la desviación estándar de la precisión. La desviación estándar mide la variabilidad o dispersión de las puntuaciones de precisión a través de los diferentes pliegues de la validación cruzada. Una desviación estándar baja sugiere que el modelo es consistente en diferentes subconjuntos de los datos, mientras que una desviación estándar alta podría indicar que el rendimiento del modelo es inestable o depende en gran medida de la división particular de los datos.\n",
    "\n",
    "### 2.3.2 Construcción de los conjuntos de entrenamiento, ajuste y evaluación\n",
    "Para evaluar la efectividad de los modelos de aprendizaje automático, utilizamos la técnica de validación cruzada con 5 pliegues. Este método implica dividir el dataset en cinco subconjuntos aproximadamente iguales. En cada iteración, uno de los subconjuntos se usa como conjunto de prueba, mientras que los otros cuatro se utilizan para entrenar el modelo. Este proceso se repite cinco veces, de modo que cada subconjunto se utiliza una vez como conjunto de prueba.\n",
    "\n",
    "### 2.3.3 ¿Por qué validación cruzada?\n",
    "Optar por la validación cruzada de 5 pliegues nos permitió utilizar todo el dataset para el entrenamiento y la evaluación, lo cual es beneficioso cuando se trabaja con conjuntos de datos que no son extremadamente grandes. Esta técnica también ayuda a mitigar el riesgo de sobreajuste al proporcionar una evaluación más completa del rendimiento del modelo en diferentes particiones del dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Experimentación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En las siguientes tablas se presentan los resultados obtenidos, mostrando la precisión promedio y la desviación estándar de los cinco pliegues generados por la validación cruzada para los diferentes algoritmos evaluados. En lugar de detallar los resultados individuales de cada pliegue, solo se exponen los promedios y las desviaciones estándar calculadas.\n",
    "\n",
    "La Tabla 1 muestra los resultados obtenidos para el algoritmo ID3 con diferentes configuraciones de max_range_split y utilizando datos preprocesados, mientras que la Tabla 2 incluye los resultados de DecisionTreeClassifier, RandomForestClassifier y el algoritmo ID3 sobre datos preprocesados en tiempo de ejecución."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <th>Algoritmo</th>\n",
    "    <th>Precisión promedio (%)</th>\n",
    "    <th>Desviación estándar (%)</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>ID3 (max_range_split = 2)</td>\n",
    "    <td>83.50</td>\n",
    "    <td>1.17</td>\n",
    "  </tr>    \n",
    "  <tr>\n",
    "    <td>ID3 (max_range_split = 3)</td>\n",
    "    <td>83.54</td>\n",
    "    <td>1.14</td>\n",
    "  </tr>    \n",
    "  <caption>Tabla 1 - Resultados de ID3 con datos preprocesados</caption>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <th>Algoritmo</th>\n",
    "    <th>Precisión promedio (%)</th>\n",
    "    <th>Desviación estándar (%)</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>DecisionTreeClassifier (criterion = 'gini')</td>\n",
    "    <td>85.46</td>\n",
    "    <td>1.55</td>\n",
    "  </tr>    \n",
    "  <tr>\n",
    "    <td>DecisionTreeClassifier (criterion = 'entropy')</td>\n",
    "    <td>83.50</td>\n",
    "    <td>1.07</td>\n",
    "  </tr>    \n",
    "  <tr>\n",
    "    <td>DecisionTreeClassifier (criterion = 'log_loss')</td>\n",
    "    <td>83.50</td>\n",
    "    <td>1.07</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>RandomForestClassifier (criterion = 'gini')</td>\n",
    "    <td>89.15</td>\n",
    "    <td>1.22</td>\n",
    "  </tr>    \n",
    "  <tr>\n",
    "    <td>RandomForestClassifier (criterion = 'entropy')</td>\n",
    "    <td>89.20</td>\n",
    "    <td>1.34</td>\n",
    "  </tr>    \n",
    "  <tr>\n",
    "    <td>RandomForestClassifier (criterion = 'log_loss')</td>\n",
    "    <td>89.20</td>\n",
    "    <td>1.34</td>\n",
    "  </tr>\n",
    "  <tr style=\"font-weight:bold\">\n",
    "    <td>ID3 (max_range_split = 2)</td>\n",
    "    <td>84.15</td>\n",
    "    <td>1.21</td>\n",
    "  </tr>    \n",
    "  <tr style=\"font-weight:bold\">\n",
    "    <td>ID3 (max_range_split = 3)</td>\n",
    "    <td>84.38</td>\n",
    "    <td>1.34</td>\n",
    "  </tr>  \n",
    "  <caption>Tabla 2 - Resultados con datos procesados durante la ejecución</caption>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una breve conclusión del trabajo realizado. Por ejemplo: \n",
    "- ¿cuándo se dieron los mejores resultados del jugador?\n",
    "- ¿encuentra alguna relación con los parámetros / oponentes/ atributos elegidos?\n",
    "- ¿cómo mejoraría los resultados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
